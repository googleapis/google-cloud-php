{"id":"dataproc\/v1\/pysparkjob","type":"","title":"Google\\Cloud\\Dataproc\\V1\\PySparkJob","name":"PySparkJob","description":"<p>A Cloud Dataproc job for running\n<a href=\"https:\/\/spark.apache.org\/docs\/0.9.0\/python-programming-guide.html\">Apache PySpark<\/a>\napplications on YARN.<\/p>\n<p>Generated from protobuf message <code>google.cloud.dataproc.v1.PySparkJob<\/code><\/p>\n<p>Extends \\Google\\Protobuf\\Internal\\Message<\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"Dataproc\/src\/V1\/PySparkJob.php#L113","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.main_python_file_uri\n","description":"<p>Required. The HCFS URI of the main Python file to use as the driver. Must be a .py file.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null},{"name":"data.args\n","description":"<p>Optional. The arguments to pass to the driver. Do not include arguments, such as <code>--conf<\/code>, that can be set as job properties, since a collision may occur that causes an incorrect job submission.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":null,"nullable":null},{"name":"data.python_file_uris\n","description":"<p>Optional. HCFS file URIs of Python files to pass to the PySpark framework. Supported file types: .py, .egg, and .zip.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":null,"nullable":null},{"name":"data.jar_file_uris\n","description":"<p>Optional. HCFS URIs of jar files to add to the CLASSPATHs of the Python driver and tasks.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":null,"nullable":null},{"name":"data.file_uris\n","description":"<p>Optional. HCFS URIs of files to be copied to the working directory of Python drivers and distributed tasks. Useful for naively parallel tasks.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":null,"nullable":null},{"name":"data.archive_uris\n","description":"<p>Optional. HCFS URIs of archives to be extracted in the working directory of .jar, .tar, .tar.gz, .tgz, and .zip.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":null,"nullable":null},{"name":"data.properties\n","description":"<p>Optional. A mapping of property names to values, used to configure PySpark. Properties that conflict with values set by the Cloud Dataproc API may be overwritten. Can include properties set in \/etc\/spark\/conf\/spark-defaults.conf and classes in user code.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","\\Google\\Protobuf\\Internal\\MapField"],"optional":null,"nullable":null},{"name":"data.logging_config\n","description":"<p>Optional. The runtime log config for job execution.<\/p>","types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/loggingconfig\">Google\\Cloud\\Dataproc\\V1\\LoggingConfig<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getMainPythonFileUri","type":"instance","name":"getMainPythonFileUri","source":"Dataproc\/src\/V1\/PySparkJob.php#L125","description":"<p>Required. The HCFS URI of the main Python file to use as the driver. Must\nbe a .py file.<\/p>\n<p>Generated from protobuf field <code>string main_python_file_uri = 1;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setMainPythonFileUri","type":"instance","name":"setMainPythonFileUri","source":"Dataproc\/src\/V1\/PySparkJob.php#L138","description":"<p>Required. The HCFS URI of the main Python file to use as the driver. Must\nbe a .py file.<\/p>\n<p>Generated from protobuf field <code>string main_python_file_uri = 1;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. The HCFS URI of the main Python file to use as the driver. Must\nbe a .py file.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getArgs","type":"instance","name":"getArgs","source":"Dataproc\/src\/V1\/PySparkJob.php#L154","description":"<p>Optional. The arguments to pass to the driver.  Do not include arguments,\nsuch as <code>--conf<\/code>, that can be set as job properties, since a collision may\noccur that causes an incorrect job submission.<\/p>\n<p>Generated from protobuf field <code>repeated string args = 2;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\RepeatedField"],"description":""}]},{"id":"setArgs","type":"instance","name":"setArgs","source":"Dataproc\/src\/V1\/PySparkJob.php#L168","description":"<p>Optional. The arguments to pass to the driver.  Do not include arguments,\nsuch as <code>--conf<\/code>, that can be set as job properties, since a collision may\noccur that causes an incorrect job submission.<\/p>\n<p>Generated from protobuf field <code>repeated string args = 2;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. The arguments to pass to the driver.  Do not include arguments,\nsuch as <code>--conf<\/code>, that can be set as job properties, since a collision may\noccur that causes an incorrect job submission.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getPythonFileUris","type":"instance","name":"getPythonFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L183","description":"<p>Optional. HCFS file URIs of Python files to pass to the PySpark\nframework. Supported file types: .py, .egg, and .zip.<\/p>\n<p>Generated from protobuf field <code>repeated string python_file_uris = 3;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\RepeatedField"],"description":""}]},{"id":"setPythonFileUris","type":"instance","name":"setPythonFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L196","description":"<p>Optional. HCFS file URIs of Python files to pass to the PySpark\nframework. Supported file types: .py, .egg, and .zip.<\/p>\n<p>Generated from protobuf field <code>repeated string python_file_uris = 3;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. HCFS file URIs of Python files to pass to the PySpark\nframework. Supported file types: .py, .egg, and .zip.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getJarFileUris","type":"instance","name":"getJarFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L211","description":"<p>Optional. HCFS URIs of jar files to add to the CLASSPATHs of the\nPython driver and tasks.<\/p>\n<p>Generated from protobuf field <code>repeated string jar_file_uris = 4;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\RepeatedField"],"description":""}]},{"id":"setJarFileUris","type":"instance","name":"setJarFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L224","description":"<p>Optional. HCFS URIs of jar files to add to the CLASSPATHs of the\nPython driver and tasks.<\/p>\n<p>Generated from protobuf field <code>repeated string jar_file_uris = 4;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. HCFS URIs of jar files to add to the CLASSPATHs of the\nPython driver and tasks.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getFileUris","type":"instance","name":"getFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L239","description":"<p>Optional. HCFS URIs of files to be copied to the working directory of\nPython drivers and distributed tasks. Useful for naively parallel tasks.<\/p>\n<p>Generated from protobuf field <code>repeated string file_uris = 5;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\RepeatedField"],"description":""}]},{"id":"setFileUris","type":"instance","name":"setFileUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L252","description":"<p>Optional. HCFS URIs of files to be copied to the working directory of\nPython drivers and distributed tasks. Useful for naively parallel tasks.<\/p>\n<p>Generated from protobuf field <code>repeated string file_uris = 5;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. HCFS URIs of files to be copied to the working directory of\nPython drivers and distributed tasks. Useful for naively parallel tasks.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getArchiveUris","type":"instance","name":"getArchiveUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L267","description":"<p>Optional. HCFS URIs of archives to be extracted in the working directory of<\/p>\n<p>.jar, .tar, .tar.gz, .tgz, and .zip.<\/p>\n<p>Generated from protobuf field <code>repeated string archive_uris = 6;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\RepeatedField"],"description":""}]},{"id":"setArchiveUris","type":"instance","name":"setArchiveUris","source":"Dataproc\/src\/V1\/PySparkJob.php#L280","description":"<p>Optional. HCFS URIs of archives to be extracted in the working directory of<\/p>\n<p>.jar, .tar, .tar.gz, .tgz, and .zip.<\/p>\n<p>Generated from protobuf field <code>repeated string archive_uris = 6;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. HCFS URIs of archives to be extracted in the working directory of<\/p>\n<p>.jar, .tar, .tar.gz, .tgz, and .zip.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string[]<\/a>","\\Google\\Protobuf\\Internal\\RepeatedField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getProperties","type":"instance","name":"getProperties","source":"Dataproc\/src\/V1\/PySparkJob.php#L297","description":"<p>Optional. A mapping of property names to values, used to configure PySpark.<\/p>\n<p>Properties that conflict with values set by the Cloud Dataproc API may be\noverwritten. Can include properties set in\n\/etc\/spark\/conf\/spark-defaults.conf and classes in user code.<\/p>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; properties = 7;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["\\Google\\Protobuf\\Internal\\MapField"],"description":""}]},{"id":"setProperties","type":"instance","name":"setProperties","source":"Dataproc\/src\/V1\/PySparkJob.php#L312","description":"<p>Optional. A mapping of property names to values, used to configure PySpark.<\/p>\n<p>Properties that conflict with values set by the Cloud Dataproc API may be\noverwritten. Can include properties set in\n\/etc\/spark\/conf\/spark-defaults.conf and classes in user code.<\/p>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; properties = 7;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. A mapping of property names to values, used to configure PySpark.<\/p>\n<p>Properties that conflict with values set by the Cloud Dataproc API may be\noverwritten. Can include properties set in\n\/etc\/spark\/conf\/spark-defaults.conf and classes in user code.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","\\Google\\Protobuf\\Internal\\MapField"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]},{"id":"getLoggingConfig","type":"instance","name":"getLoggingConfig","source":"Dataproc\/src\/V1\/PySparkJob.php#L326","description":"<p>Optional. The runtime log config for job execution.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.dataproc.v1.LoggingConfig logging_config = 8;<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/loggingconfig\">Google\\Cloud\\Dataproc\\V1\\LoggingConfig<\/a>"],"description":""}]},{"id":"setLoggingConfig","type":"instance","name":"setLoggingConfig","source":"Dataproc\/src\/V1\/PySparkJob.php#L338","description":"<p>Optional. The runtime log config for job execution.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.dataproc.v1.LoggingConfig logging_config = 8;<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Optional. The runtime log config for job execution.<\/p>\n","types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/loggingconfig\">Google\\Cloud\\Dataproc\\V1\\LoggingConfig<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"cloud-dataproc\/v0.6.0\/dataproc\/v1\/pysparkjob\">Google\\Cloud\\Dataproc\\V1\\PySparkJob<\/a>"],"description":""}]}]}