{"id":"automl\/v1beta1\/batchpredictrequest","type":"","title":"Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictRequest","name":"BatchPredictRequest","description":"<p>Request message for [PredictionService.BatchPredict][google.cloud.automl.v1beta1.PredictionService.BatchPredict].<\/p>\n<p>Generated from protobuf message <code>google.cloud.automl.v1beta1.BatchPredictRequest<\/code><\/p>\n<p>Extends <a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.13.0\/src\/Google\/Protobuf\/Internal\/Message.php\" target=\"_blank\">Google\\Protobuf\\Internal\\Message<\/a><\/p>","examples":[],"resources":[],"methods":[{"id":"__construct","type":"constructor","name":"__construct","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L175","description":"<p>Constructor.<\/p>","examples":[],"resources":[],"params":[{"name":"data","description":"<p>Optional. Data for populating the Message object.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>"],"optional":false,"nullable":null},{"name":"data.name\n","description":"<p>Required. Name of the model requested to serve the batch prediction.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":null,"nullable":null},{"name":"data.input_config\n","description":"<p>Required. The input configuration for batch prediction.<\/p>","types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictinputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictInputConfig<\/a>"],"optional":null,"nullable":null},{"name":"data.output_config\n","description":"<p>Required. The Configuration specifying where output predictions should be written.<\/p>","types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictoutputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictOutputConfig<\/a>"],"optional":null,"nullable":null},{"name":"data.params\n","description":"<p>Required. Additional domain-specific parameters for the predictions, any string must be up to 25000 characters long. <em> For Text Classification: <code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model makes predictions for a text snippet, it will only produce results that have at least this confidence score. The default is 0.5. <\/em> For Image Classification: <code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model makes predictions for an image, it will only produce results that have at least this confidence score. The default is 0.5. <em> For Image Object Detection: <code>score_threshold<\/code> - (float) When Model detects objects on the image, it will only produce bounding boxes which have at least this confidence score. Value in 0 to 1 range, default is 0.5. <code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding boxes will be produced per image. Default is 100, the requested value may be limited by server. <\/em> For Video Classification : <code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model makes predictions for a video, it will only produce results that have at least this confidence score. The default is 0.5. <code>segment_classification<\/code> - (boolean) Set to true to request segment-level classification. AutoML Video Intelligence returns labels and their confidence scores for the entire segment of the video that user specified in the request configuration. The default is &quot;true&quot;. <code>shot_classification<\/code> - (boolean) Set to true to request shot-level classification. AutoML Video Intelligence determines the boundaries for each camera shot in the entire segment of the video that user specified in the request configuration. AutoML Video Intelligence then returns labels and their confidence scores for each detected shot, along with the start and end time of the shot. WARNING: Model evaluation is not done for this classification type, the quality of it depends on training data, but there are no metrics provided to describe that quality. The default is &quot;false&quot;. <code>1s_interval_classification<\/code> - (boolean) Set to true to request classification for a video at one-second intervals. AutoML Video Intelligence returns labels and their confidence scores for each second of the entire segment of the video that user specified in the request configuration. WARNING: Model evaluation is not done for this classification type, the quality of it depends on training data, but there are no metrics provided to describe that quality. The default is &quot;false&quot;. <em> For Tables: feature_imp<span>ortan<\/span>ce - (boolean) Whether feature importance should be populated in the returned TablesAnnotations. The default is false. <\/em> For Video Object Tracking: <code>score_threshold<\/code> - (float) When Model detects objects on video frames, it will only produce bounding boxes which have at least this confidence score. Value in 0 to 1 range, default is 0.5. <code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding boxes will be returned per frame. Default is 100, the requested value may be limited by server. <code>min_bounding_box_size<\/code> - (float) Only bounding boxes with shortest edge at least that long as a relative value of video frame size will be returned. Value in 0 to 1 range. Default is 0.<\/p>","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.13.0\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"optional":null,"nullable":null}],"exceptions":[],"returns":[]},{"id":"getName","type":"instance","name":"getName","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L186","description":"<p>Required. Name of the model requested to serve the batch prediction.<\/p>\n<p>Generated from protobuf field <code>string name = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = {<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"description":""}]},{"id":"setName","type":"instance","name":"setName","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L198","description":"<p>Required. Name of the model requested to serve the batch prediction.<\/p>\n<p>Generated from protobuf field <code>string name = 1 [(.google.api.field_behavior) = REQUIRED, (.google.api.resource_reference) = {<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. Name of the model requested to serve the batch prediction.<\/p>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.string.php\" target=\"_blank\">string<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictrequest\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictRequest<\/a>"],"description":""}]},{"id":"getInputConfig","type":"instance","name":"getInputConfig","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L212","description":"<p>Required. The input configuration for batch prediction.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BatchPredictInputConfig input_config = 3 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictinputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictInputConfig<\/a>"],"description":""}]},{"id":"setInputConfig","type":"instance","name":"setInputConfig","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L224","description":"<p>Required. The input configuration for batch prediction.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BatchPredictInputConfig input_config = 3 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. The input configuration for batch prediction.<\/p>\n","types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictinputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictInputConfig<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictrequest\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictRequest<\/a>"],"description":""}]},{"id":"getOutputConfig","type":"instance","name":"getOutputConfig","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L239","description":"<p>Required. The Configuration specifying where output predictions should\nbe written.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BatchPredictOutputConfig output_config = 4 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictoutputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictOutputConfig<\/a>"],"description":""}]},{"id":"setOutputConfig","type":"instance","name":"setOutputConfig","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L252","description":"<p>Required. The Configuration specifying where output predictions should\nbe written.<\/p>\n<p>Generated from protobuf field <code>.google.cloud.automl.v1beta1.BatchPredictOutputConfig output_config = 4 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. The Configuration specifying where output predictions should\nbe written.<\/p>\n","types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictoutputconfig\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictOutputConfig<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictrequest\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictRequest<\/a>"],"description":""}]},{"id":"getParams","type":"instance","name":"getParams","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L323","description":"<p>Required. Additional domain-specific parameters for the predictions, any string must\nbe up to 25000 characters long.<\/p>\n<ul>\n<li>For Text Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a text snippet, it will only produce results\nthat have at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for an image, it will only produce results that\nhave at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Object Detection:\n<code>score_threshold<\/code> - (float) When Model detects objects on the image,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be produced per image. Default is 100, the\nrequested value may be limited by server.<\/li>\n<li>For Video Classification :\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a video, it will only produce results that\nhave at least this confidence score. The default is 0.5.\n<code>segment_classification<\/code> - (boolean) Set to true to request\nsegment-level classification. AutoML Video Intelligence returns\nlabels and their confidence scores for the entire segment of the\nvideo that user specified in the request configuration.\nThe default is &quot;true&quot;.\n<code>shot_classification<\/code> - (boolean) Set to true to request shot-level\nclassification. AutoML Video Intelligence determines the boundaries\nfor each camera shot in the entire segment of the video that user\nspecified in the request configuration. AutoML Video Intelligence\nthen returns labels and their confidence scores for each detected\nshot, along with the start and end time of the shot.\nWARNING: Model evaluation is not done for this classification type,\nthe quality of it depends on training data, but there are no metrics\nprovided to describe that quality. The default is &quot;false&quot;.\n<code>1s_interval_classification<\/code> - (boolean) Set to true to request\nclassification for a video at one-second intervals. AutoML Video\nIntelligence returns labels and their confidence scores for each\nsecond of the entire segment of the video that user specified in the\nrequest configuration.\nWARNING: Model evaluation is not done for this classification\ntype, the quality of it depends on training data, but there are no\nmetrics provided to describe that quality. The default is\n&quot;false&quot;.<\/li>\n<li>For Tables:\nfeature_imp<span>ortan<\/span>ce - (boolean) Whether feature importance\nshould be populated in the returned TablesAnnotations. The\ndefault is false.<\/li>\n<li>For Video Object Tracking:\n<code>score_threshold<\/code> - (float) When Model detects objects on video frames,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be returned per frame. Default is 100, the requested\nvalue may be limited by server.\n<code>min_bounding_box_size<\/code> - (float) Only bounding boxes with shortest edge\nat least that long as a relative value of video frame size will be\nreturned. Value in 0 to 1 range. Default is 0.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; params = 5 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[],"exceptions":[],"returns":[{"types":["<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.13.0\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"description":""}]},{"id":"setParams","type":"instance","name":"setParams","source":"AutoMl\/src\/V1beta1\/BatchPredictRequest.php#L392","description":"<p>Required. Additional domain-specific parameters for the predictions, any string must\nbe up to 25000 characters long.<\/p>\n<ul>\n<li>For Text Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a text snippet, it will only produce results\nthat have at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for an image, it will only produce results that\nhave at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Object Detection:\n<code>score_threshold<\/code> - (float) When Model detects objects on the image,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be produced per image. Default is 100, the\nrequested value may be limited by server.<\/li>\n<li>For Video Classification :\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a video, it will only produce results that\nhave at least this confidence score. The default is 0.5.\n<code>segment_classification<\/code> - (boolean) Set to true to request\nsegment-level classification. AutoML Video Intelligence returns\nlabels and their confidence scores for the entire segment of the\nvideo that user specified in the request configuration.\nThe default is &quot;true&quot;.\n<code>shot_classification<\/code> - (boolean) Set to true to request shot-level\nclassification. AutoML Video Intelligence determines the boundaries\nfor each camera shot in the entire segment of the video that user\nspecified in the request configuration. AutoML Video Intelligence\nthen returns labels and their confidence scores for each detected\nshot, along with the start and end time of the shot.\nWARNING: Model evaluation is not done for this classification type,\nthe quality of it depends on training data, but there are no metrics\nprovided to describe that quality. The default is &quot;false&quot;.\n<code>1s_interval_classification<\/code> - (boolean) Set to true to request\nclassification for a video at one-second intervals. AutoML Video\nIntelligence returns labels and their confidence scores for each\nsecond of the entire segment of the video that user specified in the\nrequest configuration.\nWARNING: Model evaluation is not done for this classification\ntype, the quality of it depends on training data, but there are no\nmetrics provided to describe that quality. The default is\n&quot;false&quot;.<\/li>\n<li>For Tables:\nfeature_imp<span>ortan<\/span>ce - (boolean) Whether feature importance\nshould be populated in the returned TablesAnnotations. The\ndefault is false.<\/li>\n<li>For Video Object Tracking:\n<code>score_threshold<\/code> - (float) When Model detects objects on video frames,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be returned per frame. Default is 100, the requested\nvalue may be limited by server.\n<code>min_bounding_box_size<\/code> - (float) Only bounding boxes with shortest edge\nat least that long as a relative value of video frame size will be\nreturned. Value in 0 to 1 range. Default is 0.<\/li>\n<\/ul>\n<p>Generated from protobuf field <code>map&lt;string, string&gt; params = 5 [(.google.api.field_behavior) = REQUIRED];<\/code><\/p>","examples":[],"resources":[],"params":[{"name":"var","description":"<p>Required. Additional domain-specific parameters for the predictions, any string must\nbe up to 25000 characters long.<\/p>\n<ul>\n<li>For Text Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a text snippet, it will only produce results\nthat have at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Classification:\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for an image, it will only produce results that\nhave at least this confidence score. The default is 0.5.<\/li>\n<li>For Image Object Detection:\n<code>score_threshold<\/code> - (float) When Model detects objects on the image,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be produced per image. Default is 100, the\nrequested value may be limited by server.<\/li>\n<li>For Video Classification :\n<code>score_threshold<\/code> - (float) A value from 0.0 to 1.0. When the model\nmakes predictions for a video, it will only produce results that\nhave at least this confidence score. The default is 0.5.\n<code>segment_classification<\/code> - (boolean) Set to true to request\nsegment-level classification. AutoML Video Intelligence returns\nlabels and their confidence scores for the entire segment of the\nvideo that user specified in the request configuration.\nThe default is &quot;true&quot;.\n<code>shot_classification<\/code> - (boolean) Set to true to request shot-level\nclassification. AutoML Video Intelligence determines the boundaries\nfor each camera shot in the entire segment of the video that user\nspecified in the request configuration. AutoML Video Intelligence\nthen returns labels and their confidence scores for each detected\nshot, along with the start and end time of the shot.\nWARNING: Model evaluation is not done for this classification type,\nthe quality of it depends on training data, but there are no metrics\nprovided to describe that quality. The default is &quot;false&quot;.\n<code>1s_interval_classification<\/code> - (boolean) Set to true to request\nclassification for a video at one-second intervals. AutoML Video\nIntelligence returns labels and their confidence scores for each\nsecond of the entire segment of the video that user specified in the\nrequest configuration.\nWARNING: Model evaluation is not done for this classification\ntype, the quality of it depends on training data, but there are no\nmetrics provided to describe that quality. The default is\n&quot;false&quot;.<\/li>\n<li>For Tables:\nfeature_imp<span>ortan<\/span>ce - (boolean) Whether feature importance\nshould be populated in the returned TablesAnnotations. The\ndefault is false.<\/li>\n<li>For Video Object Tracking:\n<code>score_threshold<\/code> - (float) When Model detects objects on video frames,\nit will only produce bounding boxes which have at least this\nconfidence score. Value in 0 to 1 range, default is 0.5.\n<code>max_bounding_box_count<\/code> - (int64) No more than this number of bounding\nboxes will be returned per frame. Default is 100, the requested\nvalue may be limited by server.\n<code>min_bounding_box_size<\/code> - (float) Only bounding boxes with shortest edge\nat least that long as a relative value of video frame size will be\nreturned. Value in 0 to 1 range. Default is 0.<\/li>\n<\/ul>\n","types":["<a href=\"http:\/\/php.net\/manual\/en\/language.types.array.php\" target=\"_blank\">array<\/a>","<a href=\"https:\/\/github.com\/protocolbuffers\/protobuf-php\/tree\/v3.13.0\/src\/Google\/Protobuf\/Internal\/MapField.php\" target=\"_blank\">Google\\Protobuf\\Internal\\MapField<\/a>"],"optional":false,"nullable":null}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"automl\/v1beta1\/batchpredictrequest\">Google\\Cloud\\AutoMl\\V1beta1\\BatchPredictRequest<\/a>"],"description":""}]}]}